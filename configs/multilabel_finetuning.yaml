# Multi-Label Classification - Fine-Tuning Configuration
# Uses different learning rates for encoder and classifier

experiment_name: multilabel_finetuning
training_mode: finetune  # freeze, full, finetune

# Model configuration
model:
  pretrained: true  # Use ImageNet weights if checkpoint_path is not set
  checkpoint_path: null  # Path to your pre-trained ResNet-50 checkpoint (e.g., "checkpoints/resnet50_best.pth")
  dropout: 0.5

# Data configuration
data:
  dataset_name: "your-username/multi-label-food-recognition"  # Update with your HuggingFace dataset
  batch_size: 16
  num_workers: 4
  image_size: 224
  split_ratio: 0.8  # Only used if dataset doesn't have predefined splits

# Training configuration
training:
  epochs: 25
  learning_rate: 0.001  # Learning rate for classifier
  encoder_lr: 0.0001  # Learning rate for encoder (10x smaller)
  weight_decay: 0.0001
  scheduler: plateau  # step, cosine, plateau
  step_size: 10
  gamma: 0.1

# Checkpoint configuration
checkpoint_dir: checkpoints/multilabel_finetune
resume_checkpoint: null  # Path to checkpoint to resume from

# Weights & Biases
use_wandb: true
wandb:
  project: multilabel-food-recognition
  run_name: multilabel_finetuning  # Custom run name for wandb

# Debug mode
debug_mode: false
debug_max_samples: 10

# Random seed
seed: 42

